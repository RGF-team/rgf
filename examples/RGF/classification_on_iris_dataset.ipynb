{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from rgf.sklearn import RGFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "rng = check_random_state(0)\n",
    "perm = rng.permutation(iris.target.size)\n",
    "iris.data = iris.data[perm]\n",
    "iris.target = iris.target[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgf = RGFClassifier(max_leaf=400,\n",
    "                    algorithm=\"RGF_Sib\",\n",
    "                    test_interval=100,\n",
    "                    verbose=True)\n",
    "gb = GradientBoostingClassifier(n_estimators=20,\n",
    "                                learning_rate=0.01,\n",
    "                                subsample=0.6,\n",
    "                                random_state=rng)\n",
    "n_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c0\n",
      "--------------------\n",
      "Sat May 27 12:13:09 2017: Reading training data ... \n",
      "Sat May 27 12:13:09 2017: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 50 trees and 100 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 100 trees and 200 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 150 trees and 300 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:09 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 200 trees and 400 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c0-01\n",
      "temp/rgf_classifier_c0-02\n",
      "temp/rgf_classifier_c0-03\n",
      "temp/rgf_classifier_c0-04\n",
      "\n",
      "Sat May 27 12:13:09 2017: Done ... \n",
      "elapsed: 0.109\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c1\n",
      "--------------------\n",
      "Sat May 27 12:13:09 2017: Reading training data ... \n",
      "Sat May 27 12:13:09 2017: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 29 trees and 101 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 57 trees and 200 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 85 trees and 300 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:09 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 115 trees and 401 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c1-01\n",
      "temp/rgf_classifier_c1-02\n",
      "temp/rgf_classifier_c1-03\n",
      "temp/rgf_classifier_c1-04\n",
      "\n",
      "Sat May 27 12:13:09 2017: Done ... \n",
      "elapsed: 0.094\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c2\n",
      "--------------------\n",
      "Sat May 27 12:13:09 2017: Reading training data ... \n",
      "Sat May 27 12:13:09 2017: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 34 trees and 100 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 71 trees and 200 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 112 trees and 300 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:09 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:09 2017: Calling optimizer with 152 trees and 400 leaves\n",
      "Sat May 27 12:13:09 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c2-01\n",
      "temp/rgf_classifier_c2-02\n",
      "temp/rgf_classifier_c2-03\n",
      "temp/rgf_classifier_c2-04\n",
      "\n",
      "Sat May 27 12:13:09 2017: Done ... \n",
      "elapsed: 0.109\n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c0-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:09 2017: Reading test data ... \n",
      "Sat May 27 12:13:09 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c0-04,#leaf=400,#tree=200\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c1-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Reading test data ... \n",
      "Sat May 27 12:13:10 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c1-04,#leaf=401,#tree=115\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c2-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Reading test data ... \n",
      "Sat May 27 12:13:10 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c2-04,#leaf=400,#tree=152\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c0\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Reading training data ... \n",
      "Sat May 27 12:13:10 2017: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 50 trees and 100 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 100 trees and 200 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 150 trees and 300 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:10 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 200 trees and 400 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c0-01\n",
      "temp/rgf_classifier_c0-02\n",
      "temp/rgf_classifier_c0-03\n",
      "temp/rgf_classifier_c0-04\n",
      "\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "elapsed: 0.109\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c1\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Reading training data ... \n",
      "Sat May 27 12:13:10 2017: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 28 trees and 100 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 57 trees and 200 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 86 trees and 300 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:10 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 115 trees and 400 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c1-01\n",
      "temp/rgf_classifier_c1-02\n",
      "temp/rgf_classifier_c1-03\n",
      "temp/rgf_classifier_c1-04\n",
      "\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "elapsed: 0.062\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c2\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Reading training data ... \n",
      "Sat May 27 12:13:10 2017: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 41 trees and 101 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 83 trees and 200 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 124 trees and 300 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:10 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:10 2017: Calling optimizer with 165 trees and 400 leaves\n",
      "Sat May 27 12:13:10 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c2-01\n",
      "temp/rgf_classifier_c2-02\n",
      "temp/rgf_classifier_c2-03\n",
      "temp/rgf_classifier_c2-04\n",
      "\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "elapsed: 0.094\n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c0-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Reading test data ... \n",
      "Sat May 27 12:13:10 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c0-04,#leaf=400,#tree=200\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c1-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:10 2017: Reading test data ... \n",
      "Sat May 27 12:13:10 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c1-04,#leaf=400,#tree=115\n",
      "Sat May 27 12:13:10 2017: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c2-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Reading test data ... \n",
      "Sat May 27 12:13:11 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c2-04,#leaf=400,#tree=165\n",
      "Sat May 27 12:13:11 2017: Done ... \n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c0\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Reading training data ... \n",
      "Sat May 27 12:13:11 2017: Start ... #train=102\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x102, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 50 trees and 100 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 100 trees and 200 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 150 trees and 300 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:11 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 200 trees and 400 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c0-01\n",
      "temp/rgf_classifier_c0-02\n",
      "temp/rgf_classifier_c0-03\n",
      "temp/rgf_classifier_c0-04\n",
      "\n",
      "Sat May 27 12:13:11 2017: Done ... \n",
      "elapsed: 0.078\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c1\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Reading training data ... \n",
      "Sat May 27 12:13:11 2017: Start ... #train=102\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x102, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 33 trees and 100 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 63 trees and 200 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 94 trees and 301 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:11 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 125 trees and 400 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c1-01\n",
      "temp/rgf_classifier_c1-02\n",
      "temp/rgf_classifier_c1-03\n",
      "temp/rgf_classifier_c1-04\n",
      "\n",
      "Sat May 27 12:13:11 2017: Done ... \n",
      "elapsed: 0.062\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF_Sib\n",
      "   train_x_fn=temp/train.data.x\n",
      "   train_y_fn=temp/train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=temp/rgf_classifier_c2\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Reading training data ... \n",
      "Sat May 27 12:13:11 2017: Start ... #train=102\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "Turning on Force_to_refresh_all\n",
      "-------------\n",
      "Training data: 4x102, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=5\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 45 trees and 101 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=1\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 86 trees and 200 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=2\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 127 trees and 301 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=3\n",
      "Sat May 27 12:13:11 2017: AzRgforest: #leaf reached max\n",
      "Sat May 27 12:13:11 2017: Calling optimizer with 169 trees and 401 leaves\n",
      "Sat May 27 12:13:11 2017: Writing model: seq#=4\n",
      "\n",
      "Generated 4 model file(s): \n",
      "temp/rgf_classifier_c2-01\n",
      "temp/rgf_classifier_c2-02\n",
      "temp/rgf_classifier_c2-03\n",
      "temp/rgf_classifier_c2-04\n",
      "\n",
      "Sat May 27 12:13:11 2017: Done ... \n",
      "elapsed: 0.078\n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c0-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Reading test data ... \n",
      "Sat May 27 12:13:11 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c0-04,#leaf=400,#tree=200\n",
      "Sat May 27 12:13:11 2017: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c1-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Reading test data ... \n",
      "Sat May 27 12:13:11 2017: Predicting ... \n",
      "elapsed: 0.015\n",
      "temp/predictions.txt: temp\\rgf_classifier_c1-04,#leaf=400,#tree=125\n",
      "Sat May 27 12:13:11 2017: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=temp\\rgf_classifier_c2-04\n",
      "   test_x_fn=temp/test.data.x\n",
      "   prediction_fn=temp/predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat May 27 12:13:11 2017: Reading test data ... \n",
      "Sat May 27 12:13:11 2017: Predicting ... \n",
      "elapsed: 0\n",
      "temp/predictions.txt: temp\\rgf_classifier_c2-04,#leaf=401,#tree=169\n",
      "Sat May 27 12:13:11 2017: Done ... \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rgf_scores = cross_val_score(rgf,\n",
    "                            iris.data,\n",
    "                            iris.target,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "gb_scores = cross_val_score(gb,\n",
    "                            iris.data,\n",
    "                            iris.target,\n",
    "                            cv=StratifiedKFold(n_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGF Classfier score: 0.95997\n",
      "Gradient Boosting Classfier score: 0.95997\n"
     ]
    }
   ],
   "source": [
    "rgf_score = sum(rgf_scores)/n_folds\n",
    "print('RGF Classfier score: {0:.5f}'.format(rgf_score))\n",
    "gb_score = sum(gb_scores)/n_folds\n",
    "print('Gradient Boosting Classfier score: {0:.5f}'.format(gb_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
